---
title: "CLAUDE.mdを育てたらClaude Codeの出力が変わった — 同一モデル比較PoCの記録"
emoji: "🧪"
type: "tech"
topics: ["claudecode", "ai", "llm", "プロンプトエンジニアリング", "開発効率化"]
published: true
---

## はじめに

「OpenClawの方がClaude Codeより賢い気がする」

同じClaude Opus 4を使っているのに、なぜか出力品質が違う。そんな直感から始まった比較実験の記録です。

結論を先に言うと、**プラットフォームの差ではなく、プロンプト設計（CLAUDE.md）が品質を決めていました。**

この記事では、3つの実験を通じて「AIコーディングエージェントは育てられる」ことを示し、すぐに使えるCLAUDE.mdテンプレートを共有します。

## 背景：なぜ「違い」を感じたのか

私は普段、OpenClaw（AIエージェントプラットフォーム）上で動くエージェント「Falak」と一緒に開発をしています。Falakには人格設定、価値観、エンジニアリング基準を定義したプロンプトが入っています。

一方、Claude Codeをデフォルト設定（CLAUDE.mdなし）で使うと、同じモデルなのに出力が「おとなしい」と感じることがありました。

- 設計の問題点を指摘しない
- 聞かれたことだけ答える
- 「Great question!」のような空虚なフィラーが入る

これはモデルの差なのか？プラットフォームの差なのか？それともプロンプトの差なのか？

**条件を揃えて検証してみました。**

## 実験設計

### 3つの条件

| 条件 | 環境 | プロンプト |
|------|------|-----------|
| ① CC素 | Claude Code | CLAUDE.mdなし |
| ② CC+CLAUDE.md | Claude Code | CLAUDE.md（人格・基準・ルール入り） |
| ③ OpenClaw | OpenClaw (Falak) | SOUL.md等（人格・基準・ルール入り） |

- **モデル**: 全条件でClaude Opus 4（統一）
- **タスク**: 同一のプロンプトを使用
- **環境**: 同一サーバー上で実行

②と③のプロンプト内容は実質同等です。②はCLAUDE.mdとして、③はOpenClawの設定ファイル（SOUL.md / AGENTS.md等）として、同じ人格・価値観・エンジニアリング基準を注入しています。

つまり、この実験の本質は **「プロンプトあり vs プロンプトなし」** の比較です。

### 3つのタスク

それぞれ異なる能力を測ります：

1. **設計タスク**（1ショット）：セマンティック検索の設計書を書かせる
2. **実装タスク**（エージェンティック）：新機能の追加（設計→実装→テスト→ドキュメント）を自律的に完了させる
3. **レビュータスク**：33,543行のコードベースをレビューさせる

## 実験1：設計タスク — 1ショットの判断力

### タスク

> cc-memoryにセマンティック検索を追加する設計書を書いてください。

### 結果

3条件すべてで、技術選定がほぼ同一に収束しました。

- 埋め込みモデル: **nomic-embed-text**（全条件で選択）
- 実行環境: **Ollama**（ローカル推論）
- 検索戦略: **RRF（Reciprocal Rank Fusion）** によるハイブリッド検索

設計書のボリュームには差がありましたが（CC素: 11-15KB、CC+CLAUDE.md: 17KB、OpenClaw: 9.6KB）、核となる技術判断は同じでした。

### 考察

**1ショットの設計タスクでは、プロンプトの有無による差はほぼ出ません。**

これは考えてみれば当然です。モデルの知識と推論能力は同じなので、同じ入力には同じ結論が出る。プロンプトが効くのは「どう振る舞うか」であって「何を知っているか」ではありません。

## 実験2：実装タスク — エージェンティックな自律性

### タスク

> cc-memoryに `memory_expire` 機能を追加してください。
> 
> 完了条件：コード修正、テスト追加（全pass）、README更新、CHANGES.md記載
> 
> **途中で質問せず、自分の判断で最後まで進めてください。**

5つの完了条件を自律的にクリアできるかを測る、エージェンティックなタスクです。

### 結果（1回目）

| 条件 | コード | テスト | README | CHANGES.md | 完了率 |
|------|--------|--------|--------|------------|--------|
| ① CC素 | ✅ | ✅ | ✅ | ❌ | 4/5 |
| ② CC+CLAUDE.md | ✅ | ✅ | ✅ | ❌ | 4/5 |
| ③ OpenClaw | ✅ | ✅ | ✅ | ✅ | 5/5 |

OpenClawだけが全完了。Claude Code（①②とも）はREADMEまで書いた時点でターン上限（max-turns: 30）に達して打ち切られました。

### 原因調査

Claude Codeの `max-turns` 設定を確認したところ、デフォルト値が実行を制限していました。OpenClawにはこの制限がなかったため、最後まで実行できていただけでした。

### 結果（2回目：ターン制限なし）

| 条件 | コード | テスト | README | CHANGES.md | 完了率 |
|------|--------|--------|--------|------------|--------|
| ① CC素 | ✅ | ✅ | ✅ | ✅ | 5/5 |
| ② CC+CLAUDE.md | ✅ | ✅ | ✅ | ✅ | 5/5 |
| ③ OpenClaw | ✅ | ✅ | ✅ | ✅ | 5/5 |

**ターン制限を揃えたら、全条件で同等の結果になりました。**

### 考察

最初の実験で「OpenClawが優秀」と見えた差は、**プラットフォームの設定差（ターン制限）** が原因でした。

これは重要な教訓です。**ツールの性能差だと思ったものが、実は設定の違いだったというケースは多い。** 比較実験では、見えないデフォルト値まで揃えないと正しい結論は出せません。

## 実験3：レビュータスク — 意見を持てるか

### タスク

> cc-memory v1（33,543行、テストゼロ）のコードレビューをしてください。

このタスクが最も差が出ました。

### 結果

**全3条件で共通の指摘：**
- 33,543行は過剰
- テストがゼロなのは問題
- 複雑な抽象化レイヤーが多すぎる

**差が出たのは「率直さ」でした：**

#### ① CC素の回答（要約）

> 「このコードベースにはいくつかの改善点があります...」

問題点は挙げるものの、トーンは控えめ。「リファクタリングを検討してもよいかもしれません」程度。

#### ② CC+CLAUDE.mdの回答（要約）

> 「No — このコードベースはリライトを推奨します。33K行でテストゼロは許容できません。」

明確に「No」と言い切り、リライトを推奨。CLAUDE.mdに「意見を持て（Have opinions）」「Yes-manになるな」と書いたことが効いています。

#### ③ OpenClaw (Falak) の回答

②と同様の率直さ。人格設定に同等の指示が入っているため。

### 考察

**レビューの「率直さ」はプロンプトで制御できます。**

モデルは本来「丁寧で控えめ」に振る舞うよう調整されています。これはカスタマーサポートには適切ですが、コードレビューでは致命的です。

「Have opinions（意見を持て）」「Don't be a yes-man（イエスマンになるな）」と明示するだけで、レビューの品質が変わりました。知識は同じなのに、**表現する許可を与えるかどうか**の違いです。

## 総合結論

### プラットフォームではなく、プロンプトが品質を決める

| 比較軸 | プラットフォーム差 | プロンプト差 |
|--------|-------------------|-------------|
| 技術的判断力 | なし | なし |
| タスク完了率 | 設定差（ターン制限等） | なし |
| レビューの率直さ | なし | **あり** |
| コード肥大化の抑止 | なし | **あり** |

同じモデルを使っている限り、知識と推論能力は同じです。差が出るのは：

1. **人格と価値観の注入** — 「意見を持て」だけでレビューが変わる
2. **エンジニアリング基準の明示** — 行数上限、完了条件チェックリスト等
3. **環境設定の差** — ターン制限、ツール利用制限等の「見えないデフォルト値」

### CLAUDE.mdで品質を上げる5つのポイント

PoCから得た知見を、すぐに使えるポイントとしてまとめます。

#### 1. 「意見を持て」と明示する

```markdown
## Who You Are
You are a senior engineering partner, not a task executor.
You have opinions and you voice them.

- Have opinions. If something is over-engineered, say so.
- Don't be a yes-man. If the user asks for something questionable, push back.
```

モデルは「丁寧に従う」のがデフォルトです。率直なフィードバックが欲しいなら、明示的に許可を与える必要があります。

#### 2. Code Health Rules（コード肥大化の防止）

```markdown
## Code Health Rules
- src/の総行数が2,000行を超えたら警告を出すこと
- 新機能追加前に行数を確認し報告
- 「この機能、本当にこのプロジェクトの責務か？」を毎回自問
```

AIは指示されたものを素直に実装します。歯止めがないと際限なく膨らみます。「行数を見ろ」「スコープを疑え」という基準を入れておくことで、自律的にブレーキをかけられます。

#### 3. Task Completion Protocol（タスク落ちの防止）

```markdown
## Task Completion Protocol
タスクを受けたら、まず完了条件をリストアップしてから着手。
実装が終わったら、完了条件を1つずつチェック:
- □ コード修正
- □ テスト追加・全pass
- □ README更新
- □ CHANGES.md記載
- □ 行数チェック

チェックが全部通るまで「完了」と言わない。
```

PoC実験2の1回目で、ドキュメント更新が漏れたのはターン制限が原因でしたが、完了条件を明示しておけばエージェント自身が「まだ終わってない」と判断できます。

#### 4. Review Checkpoints（セルフレビューの仕組み化）

```markdown
## Review Checkpoints
- 5回のファイル編集ごとに、全体のコード量と構造をセルフレビュー
- 行数が前回チェックから20%以上増えていたら、増加の妥当性を説明してから続行
```

長いエージェンティックタスクで「作業に没頭して全体を見失う」のを防ぎます。

#### 5. Proactive Engineering（言われたことだけやらない）

```markdown
## Proactive Engineering
「言われたことだけやる」ではなく「関連する作業も含めて完了させる」。
- バグ修正 → 関連テストも確認・追加
- API追加 → ドキュメントのAPI一覧も更新
- 設計変更 → 影響を受ける他のファイルも確認
```

## CLAUDE.mdテンプレート

上記のポイントをすべて含んだテンプレートを公開しています。プロジェクトに合わせてカスタマイズして使ってください。

https://github.com/0xchoux1/cc-memory/blob/main/CLAUDE-TEMPLATE.md

主な構成：
- **Who You Are** — 人格と価値観
- **Who You're Helping** — ユーザーの背景と好み
- **Engineering Standards** — 設計基準
- **Code Health Rules** — コード量の管理
- **Task Completion Protocol** — 完了条件チェック
- **Review Checkpoints** — セルフレビュー
- **Proactive Engineering** — 関連作業の自動検出
- **Memory / Context** — 教訓の蓄積

## 補足：「作る人」と「レビューする人」を分ける

PoCを通じて最も効果的だったのは、実は**CLAUDE.mdの中身ではなく運用の工夫**でした。

- Claude Codeで実装させる（作る人）
- 別のエージェント（または別セッション）でレビューさせる（レビューする人）

人間のチーム開発と同じで、作った本人は自分のコードの問題に気づきにくい。エージェントも同じです。PRベースのワークフローで「作る → レビュー → 修正」のサイクルを回すことで、品質は大きく上がります。

## まとめ

- **同じモデルなら、プラットフォームの差ではなくプロンプト設計が品質を決める**
- **「意見を持て」と書くだけでレビューの率直さが変わる**
- **Code Health Rules、Task Completion Protocol で自律的なブレーキと完了保証ができる**
- **ツールより育て方。CLAUDE.mdはエージェントの「育成計画」**

AIコーディングエージェントは、使うものではなく**育てるもの**です。CLAUDE.mdはその育成計画書。まずはテンプレートをコピーして、あなたのプロジェクトに合わせてカスタマイズしてみてください。

---

*この記事のPoC実験は、[cc-memory](https://github.com/0xchoux1/cc-memory)（マルチエージェント開発向けメモリサーバー）の開発過程で実施しました。*
